<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Multiclass classification — classification • splendid</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Multiclass classification — classification" />

<meta property="og:description" content="Run a multiclass classification algorithm on a given dataset and reference
class." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">splendid</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0.9001</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/AlineTalhouk/splendid">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Multiclass classification</h1>
    <small class="dont-index">Source: <a href='https://github.com/AlineTalhouk/splendid/blob/master/R/classification.R'><code>R/classification.R</code></a></small>
    <div class="hidden name"><code>classification.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Run a multiclass classification algorithm on a given dataset and reference
class.</p>
    
    </div>

    <pre class="usage"><span class='fu'>classification</span>(<span class='no'>data</span>, <span class='no'>class</span>, <span class='no'>algorithms</span>, <span class='kw'>rfe</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>ova</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>standardize</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>sampling</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"none"</span>, <span class='st'>"up"</span>, <span class='st'>"down"</span>, <span class='st'>"smote"</span>),
  <span class='kw'>seed_samp</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>sizes</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>trees</span> <span class='kw'>=</span> <span class='fl'>100</span>, <span class='kw'>tune</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>seed_alg</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>convert</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>data</th>
      <td><p>data frame with rows as samples, columns as features</p></td>
    </tr>
    <tr>
      <th>class</th>
      <td><p>true/reference class vector used for supervised learning</p></td>
    </tr>
    <tr>
      <th>algorithms</th>
      <td><p>character string of algorithm to use for supervised
learning. See <strong>Algorithms</strong> section for possible options.</p></td>
    </tr>
    <tr>
      <th>rfe</th>
      <td><p>logical; if <code>TRUE</code>, run Recursive Feature Elimination as a feature
selection method for "lda", "rf", and "svm" algorithms.</p></td>
    </tr>
    <tr>
      <th>ova</th>
      <td><p>logical; if <code>TRUE</code>, use the One-Vs-All approach for the <code>knn</code>
algorithm.</p></td>
    </tr>
    <tr>
      <th>standardize</th>
      <td><p>logical; if <code>TRUE</code>, the training sets are standardized on
features to have mean zero and unit variance. The test sets are
standardized using the vectors of centers and standard deviations used in
corresponding training sets.</p></td>
    </tr>
    <tr>
      <th>sampling</th>
      <td><p>the default is "none", in which no subsampling is performed.
Other options include "up" (Up-sampling the minority class), "down"
(Down-sampling the majority class), and "smote" (synthetic points for the
minority class and down-sampling the majority class). Subsampling is only
applicable to the training set.</p></td>
    </tr>
    <tr>
      <th>seed_samp</th>
      <td><p>random seed used for reproducibility in subsampling
training sets for model generation</p></td>
    </tr>
    <tr>
      <th>sizes</th>
      <td><p>the range of sizes of features to test RFE algorithm</p></td>
    </tr>
    <tr>
      <th>trees</th>
      <td><p>number of trees to use in "rf" or boosting iterations (trees) in
"adaboost"</p></td>
    </tr>
    <tr>
      <th>tune</th>
      <td><p>logical; if <code>TRUE</code>, algorithms with hyperparameters are tuned</p></td>
    </tr>
    <tr>
      <th>seed_alg</th>
      <td><p>random seed used for reproducibility when running algorithms
with an intrinsic random element (random forests)</p></td>
    </tr>
    <tr>
      <th>convert</th>
      <td><p>logical; if <code>TRUE</code>, converts all categorical variables in
<code>data</code> to dummy variables. Certain algorithms only work with such
limitations (e.g. LDA).</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>The model object from running the classification <code>algorithm</code></p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Some of the classification algorithms implemented use pre-defined values that
specify settings and options while others need to tune hyperparameters.
<code>"multinom"</code> and <code>"nnet"</code> use a maximum number of weights of 2000, in case
<code>data</code> is high dimensional and classification is time-consuming. <code>"nnet"</code>
also tunes the number of nodes (1-5) in the hidden layer. <code>"pam"</code> considers
100 thresholds when training, and uses a uniform prior. <code>"adaboost"</code> calls
<code><a href='https://rdrr.io/pkg/maboost/man/maboost.html'>maboost::maboost()</a></code> instead of <code><a href='https://rdrr.io/pkg/adabag/man/boosting.html'>adabag::boosting()</a></code> for faster performance.
As a result, we use the <code>"entrop"</code> option, which uses the KL-divergence
method and mimics adaboost. However, <code>"adaboost_m1"</code> calls
<code><a href='https://rdrr.io/pkg/adabag/man/boosting.html'>adabag::boosting()</a></code> which supports hyperparameter tuning.</p>
<p>When <code>alg = "knn"</code>, the return value is <code>NULL</code> because <code><a href='https://rdrr.io/pkg/class/man/knn.html'>class::knn()</a></code> does
not output an intermediate model object. The modelling and prediction is
performed in one step. However, the class attribute "knn" is still assigned
to the result in order to call the respective <code><a href='prediction.html'>prediction()</a></code> method. An
additional class "ova" is added if <code>ova = TRUE</code>.</p>
    
    <h2 class="hasAnchor" id="algorithms"><a class="anchor" href="#algorithms"></a>Algorithms</h2>

    <p>The classification algorithms currently supported are:</p><ul>
<li><p>Prediction Analysis for Microarrays ("pam")</p></li>
<li><p>Support Vector Machines ("svm")</p></li>
<li><p>Random Forests ("rf")</p></li>
<li><p>Linear Discriminant Analysis ("lda")</p></li>
<li><p>Shrinkage Linear Discriminant Analysis ("slda")</p></li>
<li><p>Shrinkage Diagonal Discriminant Analysis ("sdda")</p></li>
<li><p>Multinomial Logistic Regression using</p><ul>
<li><p>Generalized Linear Model with no penalization ("mlr_glm")</p></li>
<li><p>GLM with LASSO penalty ("mlr_lasso")</p></li>
<li><p>GLM with ridge penalty ("mlr_ridge")</p></li>
<li><p>Neural Networks ("mlr_nnet")</p></li>
</ul></li>
<li><p>Neural Networks ("nnet")</p></li>
<li><p>Naive Bayes ("nbayes")</p></li>
<li><p>Adaptive Boosting ("adaboost")</p></li>
<li><p>AdaBoost.M1 ("adaboost_m1")</p></li>
<li><p>Extreme Gradient Boosting ("xgboost")</p></li>
<li><p>K-Nearest Neighbours ("knn")</p></li>
</ul>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span>(<span class='no'>hgsc</span>)
<span class='no'>class</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/attr.html'>attr</a></span>(<span class='no'>hgsc</span>, <span class='st'>"class.true"</span>)
<span class='fu'>classification</span>(<span class='no'>hgsc</span>, <span class='no'>class</span>, <span class='st'>"xgboost"</span>)</div><div class='output co'>#&gt; ##### xgb.Booster
#&gt; raw: 11.5 Kb 
#&gt; call:
#&gt;   xgboost::xgb.train(params = list(objective = "multi:softprob", 
#&gt;     eval_metric = "mlogloss", num_class = dplyr::n_distinct(class)), 
#&gt;     data = xgboost::xgb.DMatrix(data = as.matrix(data), label = as.integer(class) - 
#&gt;         1), nrounds = 2)
#&gt; params (as set within xgb.train):
#&gt;   objective = "multi:softprob", eval_metric = "mlogloss", num_class = "4", silent = "1"
#&gt; xgb.attributes:
#&gt;   niter
#&gt; callbacks:
#&gt;   cb.print.evaluation(period = print_every_n)
#&gt; # of features: 321 
#&gt; niter: 2
#&gt; nfeatures : 321 </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#algorithms">Algorithms</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    <p>Derek Chiu</p>
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Derek Chiu, Aline Talhouk, Dustin Johnson.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.9000.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

