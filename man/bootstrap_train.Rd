% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bootstrap_train.R
\name{bootstrap_train}
\alias{bootstrap_train}
\title{Bootstrap training (0.632) and internal validation}
\usage{
bootstrap_train(data, class, n, seed = 1, algorithms = NULL)
}
\arguments{
\item{data}{data object with rows as samples, columns as features}

\item{class}{true/reference class vector used for supervised learning}

\item{n}{number of bootstrap replicates to generate}

\item{seed}{random seed used for reproducibility in bootstrapping results}

\item{algorithms}{character vector of algorithm names to use for supervised 
learning. See Details for possible options. This argument is \code{NULL} by
default, in which case uses all implemented algorithms.}
}
\value{
A nested list with 2 elements
\item{model}{A list with an element for each algorithm, each of which is a 
list with length \code{n}}
\item{eval}{For each bootstrap sample, we can calculate various evaluation 
measures for the predicted classes from each algorithm. Evaluation measures 
include macro-averaged precision/recall/F1-score, micro-averaged precision, 
and (micro-averaged MCC) }
}
\description{
Training sets are bootstrap replicates of the original data sampled with 
replacement. Test sets comprise of all remaining samples left out from each 
training set, also called Out-Of-Bag samples. This framework uses the 0.632
bootstrap rule for large n.
Supervised learning classification algorithms are trained on bootstrap 
replicates and are evaluated on the out of bag data (not used for training).
}
\details{
The classification algorithms currently supported are: Linear Discriminant 
Analysis ("lda"), Random Forests ("rf"), Multinomial Classification 
("multinom"), Neural Networks ("nnet"), K-Nearest Neighbours, ("knn"), 
Support Vector Machines ("svm"), Prediction Analysis for Microarrays ("pam"),
Adaptive Boosting ("adaboost"), Extreme Gradient Boosting ("xgboost"), Naive 
Bayes ("nb"), and Generalized Linear Models using Elastic Net model paths 
("glmnet").
}
\examples{
data(hgsc)
class <- stringr::str_split_fixed(rownames(hgsc), "_", n = 2)[, 2]
sl_result <- bootstrap_train(hgsc, class, n = 1, algorithms = c("lda", "knn",
"svm"))
}
