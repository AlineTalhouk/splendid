% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/splendid.R
\name{splendid}
\alias{splendid}
\title{Ensemble framework for Supervised Learning classification problems}
\usage{
splendid(data, class, n, seed = 1, algorithms = NULL)
}
\arguments{
\item{data}{data object with rows as samples, columns as features}

\item{class}{true/reference class vector used for supervised learning}

\item{n}{number of bootstrap replicates to generate}

\item{seed}{random seed used for reproducibility in bootstrapping results}

\item{algorithms}{character vector of algorithm names to use for supervised 
learning. See Details for possible options. This argument is \code{NULL} by
default, in which case uses all implemented algorithms.}
}
\value{
A nested list with five elements
\item{model}{A list with an element for each algorithm, each of which is a 
list with length \code{n}. Shows the model object for each algorithm and
bootstrap replicate on the training set.}
\item{pred}{A list with an element for each algorithm, each of which is a 
list with length \code{n}. Shows the predicted classes for each algorithm and
bootstrap replicate on the test set.}
\item{eval}{For each bootstrap sample, we can calculate various evaluation 
measures for the predicted classes from each algorithm. Evaluation measures 
include overall accuracy, average accuracy, and micro-averaged precision, 
recall, and F1-score. The micro-averaged measures are computed from the sum 
of all One-Vs-All confusion matrices. The return value of \code{eval} is a 
tibble that shows the median of the evaluation measures across bootstrap
samples, for each classification algorithm.}
\item{best.alg}{A length \code{n} vector of the top performing algorithms in
each bootstrap sample as defined by the evaluation measures and using Rank
Aggregation.}
\item{ensemble}{A predicted class vector of the entire dataset using the 
ensemble classifier: majority voting is used for class representation of each
sample across different algortithms used.}
}
\description{
Supervised learning classification algorithms are performed on bootstrap 
replicates and an ensemble classifier is built and evaluated across these 
variants.
}
\details{
Training sets are bootstrap replicates of the original data sampled with 
replacement. Test sets comprise of all remaining samples left out from each 
training set, also called Out-Of-Bag samples. This framework uses the 0.632
bootstrap rule for large n.

The classification algorithms currently supported are: Linear Discriminant 
Analysis ("lda"), Random Forests ("rf"), Multinomial Classification 
("multinom"), Neural Networks ("nnet"), K-Nearest Neighbours, ("knn"), 
Support Vector Machines ("svm"), Prediction Analysis for Microarrays ("pam"),
Adaptive Boosting ("adaboost"), Naive Bayes ("nb"), and Generalized Linear 
Models using Elastic Net model paths ("glmnet").

An ensemble classifier is constructed using Rank Aggregation across multiple
evaluation measures such as accuracy, precision, recall, and F1-score.
}
\examples{
data(hgsc)
class <- stringr::str_split_fixed(rownames(hgsc), "_", n = 2)[, 2]
sl_result <- splendid(hgsc, class, n = 2, algorithms = c("lda", "knn",
"svm"))
}
\author{
Derek Chiu
}
