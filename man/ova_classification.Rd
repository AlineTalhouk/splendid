% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ova.R
\name{ova_classification}
\alias{ova_classification}
\title{One-Vs-All training approach}
\usage{
ova_classification(
  data,
  class,
  algorithms,
  rfe = FALSE,
  ova = FALSE,
  standardize = FALSE,
  sampling = c("none", "up", "down", "smote"),
  seed_samp = NULL,
  trees = 100,
  tune = FALSE,
  seed_alg = NULL
)
}
\arguments{
\item{data}{data frame with rows as samples, columns as features}

\item{class}{true/reference class vector used for supervised learning}

\item{algorithms}{character string of algorithm to use for supervised
learning. See \strong{Algorithms} section for possible options.}

\item{rfe}{logical; if \code{TRUE}, run Recursive Feature Elimination as a feature
selection method for "lda", "rf", and "svm" algorithms.}

\item{ova}{logical; if \code{TRUE}, use the One-Vs-All approach for the \code{knn}
algorithm.}

\item{standardize}{logical; if \code{TRUE}, the training sets are standardized on
features to have mean zero and unit variance. The test sets are
standardized using the vectors of centers and standard deviations used in
corresponding training sets.}

\item{sampling}{the default is "none", in which no subsampling is performed.
Other options include "up" (Up-sampling the minority class), "down"
(Down-sampling the majority class), and "smote" (synthetic points for the
minority class and down-sampling the majority class). Subsampling is only
applicable to the training set.}

\item{seed_samp}{random seed used for reproducibility in subsampling
training sets for model generation}

\item{trees}{number of trees to use in "rf"}

\item{tune}{logical; if \code{TRUE}, algorithms with hyperparameters are tuned}

\item{seed_alg}{random seed used for reproducibility when running algorithms
with an intrinsic random element (random forests)}
}
\value{
list of binary classifier fits on each class
}
\description{
One-Vs-All training approach
}
\author{
Dustin Johnson, Derek Chiu
}
